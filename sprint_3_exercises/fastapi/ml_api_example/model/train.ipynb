{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtYvddAuiscn"
      },
      "source": [
        "## EDA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "MP6z9Kvciscr",
        "outputId": "426f4bf8-25da-44aa-d2d7-78a3a36e2994"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"diabetes_prediction_dataset.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f-lN2Bgisct"
      },
      "source": [
        "## Feature engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81cjYMn_iscu",
        "outputId": "cad0a7fb-69cb-4af2-af58-232f99468a97"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Separate features and target (diabetes will be our target)\n",
        "x = df[df.columns.drop(\"diabetes\")]\n",
        "y = df[\"diabetes\"]\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ADB85SGiscu",
        "outputId": "a9b4648d-3752-48a3-cdaf-25e397c539fc"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "\n",
        "numerical_features = x_train.select_dtypes(include=\"number\").columns.tolist()\n",
        "print(f\"There are {len(numerical_features)} numerical features: {numerical_features}\\n\")\n",
        "\n",
        "string_features = x_train.select_dtypes(exclude=\"number\").columns.tolist()\n",
        "print(f\"There are {len(string_features)} string features: {string_features}\\n\")\n",
        "\n",
        "# Pipeline for numeric features\n",
        "numeric_pipeline = Pipeline(\n",
        "    steps=[(\"impute\", SimpleImputer(strategy=\"mean\")), (\"scale\", StandardScaler())]\n",
        ")\n",
        "\n",
        "# Pipeline for string features\n",
        "string_pipeline = Pipeline(\n",
        "    steps=[\n",
        "        (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"encode\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Now let's merge both pipeline into one single pre-processing object\n",
        "# We can use ColumnTransformer for this\n",
        "full_processor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"number\", numeric_pipeline, numerical_features),\n",
        "        (\"string\", string_pipeline, string_features),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2u8qlWqPiscv",
        "outputId": "bef22931-5623-4bd9-cdd6-ebf212c2481a"
      },
      "outputs": [],
      "source": [
        "x_train = full_processor.fit_transform(x_train)\n",
        "x_test = full_processor.transform(x_test)\n",
        "\n",
        "print(x_train.shape, x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"preprocessor.pkl\", \"wb\") as f:\n",
        "    pickle.dump(full_processor, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcKCLmQ5lvGE"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "x_train, y_train = rus.fit_resample(x_train, y_train)\n",
        "print(sorted(Counter(y_train).items()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_CjF4dPiscv"
      },
      "source": [
        "## Model definition and training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(64, 16),\n",
        "    max_iter=1000,\n",
        "    early_stopping=True,\n",
        "    random_state=42,\n",
        ")\n",
        "mlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlp.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = mlp.predict(x_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(mlp, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model definition and training (Keras version)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAWKJbHeiscw",
        "outputId": "8f4b65cb-23c0-4c14-d734-b6119db26be2"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "\n",
        "# Let's create a simple MLP with Keras\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Dense(64, input_dim=x_train.shape[1], activation=\"relu\"))\n",
        "model.add(layers.Dense(16, activation=\"relu\"))\n",
        "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNZISMUIiscx"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbjLUiRaiscx",
        "outputId": "eae1835d-51d1-42f5-863d-cda7e53c889e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    min_delta=0.001,\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "# add class_weight to balance the classes from scikit-learn\n",
        "class_weights = compute_class_weight(\"balanced\", classes=np.unique(y_train), y=y_train)\n",
        "class_weights = {0: class_weights[0], 1: class_weights[1]}\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping],\n",
        "    class_weight=class_weights,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FnsFYmniscx"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# def plot_history(history):\n",
        "#     # Plot training & validation accuracy values\n",
        "#     plt.plot(history.history[\"accuracy\"])\n",
        "#     plt.plot(history.history[\"val_accuracy\"])\n",
        "#     plt.title(\"Model accuracy\")\n",
        "#     plt.ylabel(\"Accuracy\")\n",
        "#     plt.xlabel(\"Epoch\")\n",
        "#     plt.legend([\"Train\", \"Test\"], loc=\"upper left\")\n",
        "#     plt.show()\n",
        "\n",
        "#     # Plot training & validation loss values\n",
        "#     plt.plot(history.history[\"loss\"])\n",
        "#     plt.plot(history.history[\"val_loss\"])\n",
        "#     plt.title(\"Model loss\")\n",
        "#     plt.ylabel(\"Loss\")\n",
        "#     plt.xlabel(\"Epoch\")\n",
        "#     plt.legend([\"Train\", \"Test\"], loc=\"upper left\")\n",
        "#     plt.show()\n",
        "\n",
        "\n",
        "# plot_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vZt6axRiscx",
        "outputId": "8b320cc2-ad3e-4ffe-a8b5-147917b52053"
      },
      "outputs": [],
      "source": [
        "# evaluate precision and recall and f1-score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred_proba = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofJUg7FhvE6V",
        "outputId": "29236d00-1288-4b10-a029-3f627e5090f0"
      },
      "outputs": [],
      "source": [
        "y_pred = y_pred_proba > 0.95\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "XxJazwneiscx",
        "outputId": "5e1ae252-070f-48f3-d94b-0b0444fb04f4"
      },
      "outputs": [],
      "source": [
        "# show confusion matrix plotted with seaborn\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred, normalize=\"pred\")\n",
        "sns.heatmap(cm, annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ac-A2KLFw4vI"
      },
      "outputs": [],
      "source": [
        "model.save(\"model.keras\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "anyone",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
